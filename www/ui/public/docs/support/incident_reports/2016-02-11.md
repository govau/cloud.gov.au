## February 11, 2016 incident report

Yesterday the DIBP Citizenship Appointment Booking service was unavailable for 14 minutes. We understand the importance of keeping these services up for the public, especially during beta when users are interacting with these services for the first time. We are really sorry for the unavailability, and will share with you the events that took place, and the steps we’re taking to ensure a failure of this type doesn't happen again.

### Background

The DIBP application is running on a hosting platform we make available to both teams in the transformation programme, and internally to the DTO. The hosting platform is built with Pivotal Cloud Foundry (PCF), an industry leading Platform as a Service technology. PCF is deployed on top of Amazon Web Services (AWS), the industry leader Infrastructure as a Service provider.

The DIBP application was unavailable because of a failure in the underlying hosting platform. The hosting platform is a complex system with many moving parts, however it is designed to be reliable (applications continue to work in the event of single or multiple failures) and fault tolerant (the system heals itself when it detects a failure). In this case the system was fault tolerant, but it was not reliable – causing the DIBP application to become unavailable.

### What happened

This is the timeline of events that occurred on Thursday February 11 2016, starting at 10.42am:

 - 10.42: the DIBP Citizenship Appointment Booking application became unavailable due to a hosting platform failure.
 - 10.46: DTO Infrastructure & Platform engineers were alerted to the application being unavailable.
 - 10.56: The platform auto-healed with no human intervention, and the application became available again.

This is what we have learnt about what happened:

 - An AWS EC2 instance running a Diego Brain was terminated.
 - To contextualise, [have a look at how](https://github.com/cloudfoundry-incubator/diego-design-notes/raw/master/diego-overview.png) the Diego Brain fits in to the [Diego Architecture](https://github.com/cloudfoundry-incubator/diego-design-notes) (the Diego Brain is a blue box at the bottom of the diagram).
 - The Diego Brain is responsible for publishing information about where applications are running on the platform.
 - This information is used by the router to route requests to the running application, where ever it may be running on the platform.
 - While this may sound unnecessarily complicated, this allows workloads to be shifted across the platform when the underlying infrastructure fails or is being upgraded, ensuring fault tolerance.
 - It is unclear what caused the instance to be terminated, however it could either be AWS EC2 service killing the instance, or because the PCF Operations Manager failed a health check and reprovisioned the instance.
 - What we do know is that the PCF Operations Manager has no logs indicating it terminated an instance, so we assert that AWS killed the EC2 instance.

Because the Diego Brain periodically re-publishes all routing information with a Time To Live (TTL), when the Diego Brain instance was terminated, the routing information expired in the database.

This meant that requests were unable to be routed to the application.

The PCF Operations Manager detected the EC2 instance had disappeared, and initiated an auto recovery to create a replacement Diego Brain instance, and bring it into service

While the EC2 instance running the Diego Brain was offline, the application was unavailable.

### Contributing factors

After conducting a Post Incident Review, we have determined the two direct contributing factors were:

 1. A single point of failure introduced during the setup of the platform, due to time pressures on delivery. We needed to get the platform running so the application could be hosted, and we missed the HA step.
 2. EC2 instances fail periodically, without warning. This is part of the Amazon design, and the platform is designed and built to recover when these failures happen.

### What we're doing to fix this

This was the first failure of the platform that we have experienced since it went live on January 22, 2016. We see this platform failure as both an excellent opportunity to learn about how complex systems fail, and how we can improve the reliability and quality of service the Infrastructure & Platforms team provides.

 - We will remove the single point of failure by increasing the number of Diego Brain instances.
 - We will audit the currently deployed instances to verify we meet the recommended counts of instance types for a fully Highly Available PCF deployment.
 - We will make improvements to the logging so we can ascertain exactly what has happened on the underlying EC2 infrastructure, during incidents and post-hoc analysis.
 - We will make improvements to the monitoring so we more frequently probe the running applications, and detect failures earlier.
 - We will improve our escalation process to notify engineers more aggressively when failures are detected, and provide a mechanism for people to contact us for undetected failures.

### Conclusion

All of us on the Infrastructure & Platforms team would like to apologize for the impact of this outage. We will continue to analyze the events leading up to this incident and the steps we took to restore service. This work will guide us as we improve the systems and processes that power the DTO Platform.

If you have any questions, please don't hesitate to contact the cloud.gov.au team at support@cloud.gov.au.
